{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import collections\n",
    "sys.path.extend(['../input/bert-joint-baseline/'])\n",
    "\n",
    "import bert_utils\n",
    "from bert_utils import AnswerType\n",
    "import modeling \n",
    "\n",
    "import tokenization\n",
    "import json\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "on_kaggle_server = os.path.exists('/kaggle')\n",
    "nq_test_file = '../input/tensorflow2-question-answering/simplified-nq-test.jsonl' \n",
    "nq_train_file = '../input/tensorflow2-question-answering/simplified-nq-train.jsonl'\n",
    "public_dataset = os.path.getsize(nq_test_file)<20_000_000\n",
    "private_dataset = os.path.getsize(nq_test_file)>=20_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    import importlib\n",
    "    importlib.reload(bert_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "config = {'attention_probs_dropout_prob':0.1,\n",
    "'hidden_act':'gelu', # 'gelu',\n",
    "'hidden_dropout_prob':0.1,\n",
    "'hidden_size':1024,\n",
    "'initializer_range':0.02,\n",
    "'intermediate_size':4096,\n",
    "'max_position_embeddings':512,\n",
    "'num_attention_heads':16,\n",
    "'num_hidden_layers':24,\n",
    "'type_vocab_size':2,\n",
    "'vocab_size':30522}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class TDense(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 output_size,\n",
    "                 kernel_initializer=None,\n",
    "                 bias_initializer=\"zeros\",\n",
    "                **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.output_size = output_size\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "    def build(self,input_shape):\n",
    "        dtype = tf.as_dtype(self.dtype or tf.keras.backend.floatx())\n",
    "        if not (dtype.is_floating or dtype.is_complex):\n",
    "          raise TypeError(\"Unable to build `TDense` layer with \"\n",
    "                          \"non-floating point (and non-complex) \"\n",
    "                          \"dtype %s\" % (dtype,))\n",
    "        input_shape = tf.TensorShape(input_shape)\n",
    "        if tf.compat.dimension_value(input_shape[-1]) is None:\n",
    "          raise ValueError(\"The last dimension of the inputs to \"\n",
    "                           \"`TDense` should be defined. \"\n",
    "                           \"Found `None`.\")\n",
    "        last_dim = tf.compat.dimension_value(input_shape[-1])\n",
    "        self.input_spec = tf.keras.layers.InputSpec(min_ndim=3, axes={-1: last_dim})\n",
    "        self.kernel = self.add_weight(\n",
    "            \"kernel\",\n",
    "            shape=[self.output_size,last_dim],\n",
    "            initializer=self.kernel_initializer,\n",
    "            dtype=self.dtype,\n",
    "            trainable=True)\n",
    "        self.bias = self.add_weight(\n",
    "            \"bias\",\n",
    "            shape=[self.output_size],\n",
    "            initializer=self.bias_initializer,\n",
    "            dtype=self.dtype,\n",
    "            trainable=True)\n",
    "        super(TDense, self).build(input_shape)\n",
    "    def call(self,x):\n",
    "        return tf.matmul(x,self.kernel,transpose_b=True)+self.bias\n",
    "    \n",
    "def mk_model(config):\n",
    "    seq_len = config['max_position_embeddings']\n",
    "    unique_id  = tf.keras.Input(shape=(1,),dtype=tf.int64,name='unique_id')\n",
    "    input_ids   = tf.keras.Input(shape=(seq_len,),dtype=tf.int32,name='input_ids')\n",
    "    input_mask  = tf.keras.Input(shape=(seq_len,),dtype=tf.int32,name='input_mask')\n",
    "    segment_ids = tf.keras.Input(shape=(seq_len,),dtype=tf.int32,name='segment_ids')\n",
    "    BERT = modeling.BertModel(config=config,name='bert')\n",
    "    pooled_output, sequence_output = BERT(input_word_ids=input_ids,\n",
    "                                          input_mask=input_mask,\n",
    "                                          input_type_ids=segment_ids)\n",
    "    \n",
    "    logits = TDense(2,name='logits')(sequence_output)\n",
    "    start_logits,end_logits = tf.split(logits,axis=-1,num_or_size_splits= 2,name='split')\n",
    "    start_logits = tf.squeeze(start_logits,axis=-1,name='start_squeeze')\n",
    "    end_logits   = tf.squeeze(end_logits,  axis=-1,name='end_squeeze')\n",
    "    \n",
    "    ans_type      = TDense(5,name='ans_type')(pooled_output)\n",
    "    return tf.keras.Model([input_ for input_ in [unique_id,input_ids,input_mask,segment_ids] \n",
    "                           if input_ is not None],\n",
    "                          [unique_id,start_logits,end_logits,ans_type],\n",
    "                          name='bert-baseline')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model= mk_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bert-baseline\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (BertModel)                ((None, 1024), (None 335141888   input_ids[0][0]                  \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "logits (TDense)                 (None, 512, 2)       2050        bert[0][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_split (TensorFlowOp [(None, 512, 1), (No 0           logits[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "unique_id (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_start_squeeze (Tens [(None, 512)]        0           tf_op_layer_split[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_end_squeeze (Tensor [(None, 512)]        0           tf_op_layer_split[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "ans_type (TDense)               (None, 5)            5125        bert[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 335,149,063\n",
      "Trainable params: 335,149,063\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x6c9e200f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpkt = tf.train.Checkpoint(model=model)\n",
    "cpkt.restore('../input/bert-joint-baseline/model_cpkt-1').assert_consumed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "class DummyObject:\n",
    "    def __init__(self,**kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "FLAGS=DummyObject(skip_nested_contexts=True, #True\n",
    "                  max_position=50,\n",
    "                  max_contexts=48,\n",
    "                  max_query_length=64,\n",
    "                  max_seq_length=512, #512\n",
    "                  doc_stride=128,\n",
    "                  include_unknowns=0.02, #0.02\n",
    "                  n_best_size=5, #20\n",
    "                  max_answer_length=30, #30\n",
    "                  \n",
    "                  warmup_proportion=0.1,\n",
    "                  learning_rate=1e-5,\n",
    "                  num_train_epochs=3.0,\n",
    "                  train_batch_size=32,\n",
    "                  num_train_steps=100000,\n",
    "                  num_warmup_steps=10000,\n",
    "                  max_eval_steps=100,\n",
    "                  use_tpu=False,\n",
    "                  eval_batch_size=8, \n",
    "                  max_predictions_per_seq=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "eval_records = \"../input/bert-joint-baseline/nq-test.tfrecords\"\n",
    "\n",
    "if on_kaggle_server and private_dataset:\n",
    "    eval_records='nq-test.tfrecords'\n",
    "if not os.path.exists(eval_records):\n",
    "    \n",
    "    eval_writer = bert_utils.FeatureWriter(\n",
    "        filename=os.path.join(eval_records),\n",
    "        is_training=False)\n",
    "\n",
    "    tokenizer = tokenization.FullTokenizer(vocab_file='../input/bert-joint-baseline/vocab-nq.txt', \n",
    "                                           do_lower_case=True)\n",
    "\n",
    "    features = []\n",
    "    convert = bert_utils.ConvertExamples2Features(tokenizer=tokenizer,\n",
    "                                                   is_training=False,\n",
    "                                                   output_fn=eval_writer.process_feature,\n",
    "                                                   collect_stat=False)\n",
    "\n",
    "    n_examples = 0\n",
    "    tqdm_notebook= tqdm.tqdm_notebook if not on_kaggle_server else None\n",
    "    for examples in bert_utils.nq_examples_iter(input_file=nq_test_file, \n",
    "                                           is_training=False,\n",
    "                                           tqdm=tqdm_notebook):\n",
    "        for example in examples:\n",
    "            n_examples += convert(example)\n",
    "\n",
    "    eval_writer.close()\n",
    "    print('number of test examples: %d, written to file: %d' % (n_examples,eval_writer.num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "seq_length = FLAGS.max_seq_length #config['max_position_embeddings']\n",
    "name_to_features = {\n",
    "      \"unique_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "      \"input_ids\": tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "      \"input_mask\": tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "      \"segment_ids\": tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "  }\n",
    "\n",
    "def _decode_record(record, name_to_features=name_to_features):\n",
    "    \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "    example = tf.io.parse_single_example(serialized=record, features=name_to_features)\n",
    "\n",
    "    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "    # So cast all int64 to int32.\n",
    "    for name in list(example.keys()):\n",
    "        t = example[name]\n",
    "        if name != 'unique_id': #t.dtype == tf.int64:\n",
    "            t = tf.cast(t, dtype=tf.int64)\n",
    "        example[name] = t\n",
    "\n",
    "    return example\n",
    "\n",
    "def _decode_tokens(record):\n",
    "    return tf.io.parse_single_example(serialized=record, \n",
    "                                      features={\n",
    "                                          \"unique_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "                                          \"token_map\" :  tf.io.FixedLenFeature([seq_length], tf.int64)\n",
    "                                      })\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "raw_ds = tf.data.TFRecordDataset(eval_records)\n",
    "token_map_ds = raw_ds.map(_decode_tokens)\n",
    "decoded_ds = raw_ds.map(_decode_record)\n",
    "ds = decoded_ds.batch(batch_size=32,drop_remainder=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b9066d0e1f6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "result=model.predict_generator(ds,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-06839ae02fa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m np.savez_compressed('bert-joint-baseline-output.npz',\n\u001b[1;32m      2\u001b[0m                     **dict(zip(['uniqe_id','start_logits','end_logits','answer_type_logits'],\n\u001b[0;32m----> 3\u001b[0;31m                                result)))\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "np.savez_compressed('bert-joint-baseline-output.npz',\n",
    "                    **dict(zip(['uniqe_id','start_logits','end_logits','answer_type_logits'],\n",
    "                               result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# class ScoreSummary(object):\n",
    "#     def __init__(self):\n",
    "#         self.predicted_label = None\n",
    "#         self.short_span_score = None\n",
    "#         self.cls_token_score = None\n",
    "#         self.answer_type_logits = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScoreSummary = collections.namedtuple(\"ScoreSummary\", [\"short_span_score\", \"cls_token_score\",\n",
    "                                                       \"answer_type_logits\", \"answer_type\",\n",
    "                                                       \"start_logits\", \"end_logits\", \"unique_id\",\n",
    "                                                      \"start_idx_in_chunk\", \"end_idx_in_chunk\"])\n",
    "def empty_score_summary():\n",
    "    return ScoreSummary(None, None, None, None, None, None, None, None, None)\n",
    "    \n",
    "Span = collections.namedtuple(\"Span\", [\"start_token_idx\", \"end_token_idx\", \"score\", \"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "class EvalExample(object):\n",
    "  \"\"\"Eval data available for a single example.\"\"\"\n",
    "  def __init__(self, example_id, candidates):\n",
    "    self.example_id = example_id\n",
    "    self.candidates = candidates\n",
    "    self.results = {}\n",
    "    self.features = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "def get_best_indexes(logits, n_best_size):\n",
    "  \"\"\"Get the n-best logits from a list.\"\"\"\n",
    "  index_and_score = sorted(\n",
    "      enumerate(logits[1:], 1), key=lambda x: x[1], reverse=True)\n",
    "  best_indexes = []\n",
    "  for i in range(len(index_and_score)):\n",
    "    if i >= n_best_size:\n",
    "      break\n",
    "    best_indexes.append(index_and_score[i][0])\n",
    "  return best_indexes\n",
    "\n",
    "def top_k_indices(logits,n_best_size,token_map):\n",
    "    indices = np.argsort(logits[1:])+1\n",
    "    indices = indices[token_map[indices]!=-1]\n",
    "    return indices[-n_best_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(span):\n",
    "    start_end = []\n",
    "    for s in span:\n",
    "        cont = 0\n",
    "        if not start_end:\n",
    "            start_end.append(s)\n",
    "            cont += 1\n",
    "        else:\n",
    "            for i in range(len(start_end)):\n",
    "                if start_end[i].start_token_idx == s.start_token_idx and \\\n",
    "                start_end[i].end_token_idx == s.end_token_idx:\n",
    "                    cont += 1\n",
    "        if cont == 0:\n",
    "            start_end.append(s)\n",
    "            \n",
    "    return start_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_short_long_span_answers(predictions, example):\n",
    "    \n",
    "    sorted_predictions = sorted(predictions, reverse=True)\n",
    "    short_span = []\n",
    "    long_span = []\n",
    "    for prediction in sorted_predictions:\n",
    "        score, _, summary, start_span, end_span = prediction\n",
    "        # get scores > zero\n",
    "        if score > 0:\n",
    "            short_span.append(Span(int(start_span), int(end_span), float(score), summary))\n",
    "\n",
    "    short_span = remove_duplicates(short_span)\n",
    "\n",
    "    for s in range(len(short_span)):\n",
    "        for c in example.candidates:\n",
    "            start = short_span[s].start_token_idx\n",
    "            end = short_span[s].end_token_idx\n",
    "            ## print(c['top_level'],c['start_token'],start,c['end_token'],end)\n",
    "            if c[\"top_level\"] and c[\"start_token\"] <= start and c[\"end_token\"] >= end:\n",
    "                long_span.append(Span(int(c[\"start_token\"]), int(c[\"end_token\"]),\n",
    "                                      float(short_span[s].score), short_span[s].summary))\n",
    "                break\n",
    "    long_span = remove_duplicates(long_span)\n",
    "    \n",
    "    if not long_span:\n",
    "        long_span = [Span(-1, -1, -10000.0, empty_score_summary())]\n",
    "    if not short_span:\n",
    "        short_span = [Span(-1, -1, -10000.0, empty_score_summary())]\n",
    "        \n",
    "    \n",
    "    return short_span, long_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "def compute_predictions(example):\n",
    "    \"\"\"Converts an example into an NQEval object for evaluation.\"\"\"\n",
    "    predictions = []\n",
    "    n_best_size = FLAGS.n_best_size\n",
    "    max_answer_length = FLAGS.max_answer_length\n",
    "    i = 0\n",
    "    for unique_id, result in example.results.items():\n",
    "        if unique_id not in example.features:\n",
    "            raise ValueError(\"No feature found with unique_id:\", unique_id)\n",
    "        token_map = np.array(example.features[unique_id][\"token_map\"]) #.int64_list.value\n",
    "        start_indexes = top_k_indices(result.start_logits,n_best_size,token_map)\n",
    "        if len(start_indexes)==0:\n",
    "            continue\n",
    "        end_indexes   = top_k_indices(result.end_logits,n_best_size,token_map)\n",
    "        if len(end_indexes)==0:\n",
    "            continue\n",
    "        indexes = np.array(list(np.broadcast(start_indexes[None],end_indexes[:,None])))  \n",
    "        indexes = indexes[(indexes[:,0] < indexes[:,1]) * (indexes[:,1] - indexes[:,0] < max_answer_length)]\n",
    "        for _, (start_index,end_index) in enumerate(indexes):  \n",
    "            short_span_score = (\n",
    "                result.start_logits[start_index] +\n",
    "                result.end_logits[end_index])\n",
    "            cls_token_score = (\n",
    "                result.start_logits[0] + result.end_logits[0])\n",
    "            answer_type_logits = result.answer_type_logits - result.answer_type_logits.mean()\n",
    "            answer_type = int(np.argmax(answer_type_logits))\n",
    "            \n",
    "            start_logits = list(result.start_logits)\n",
    "            end_logits = list(result.end_logits)\n",
    "            start_idx_in_chunk = start_index\n",
    "            end_idx_in_chunk = end_index\n",
    "            \n",
    "            summary = ScoreSummary(short_span_score, cls_token_score, list(answer_type_logits),\n",
    "                                   answer_type, start_logits, end_logits, unique_id,\n",
    "                                   start_idx_in_chunk, end_idx_in_chunk)\n",
    "            \n",
    "            start_span = token_map[start_index]\n",
    "            end_span = token_map[end_index] + 1\n",
    "\n",
    "            # Span logits minus the cls logits seems to be close to the best.\n",
    "            score = summary.short_span_score - summary.cls_token_score\n",
    "            predictions.append((score, i, summary, start_span, end_span))\n",
    "            i += 1 # to break ties\n",
    "\n",
    "    # Default empty prediction.\n",
    "    short_spans = [Span(-1, -1, -10000.0, empty_score_summary())]\n",
    "    long_spans  = [Span(-1, -1, -10000.0, empty_score_summary())]\n",
    "\n",
    "    if predictions:\n",
    "        short_spans, long_spans = get_short_long_span_answers(predictions, example)\n",
    "      \n",
    "    predictions_summary = {\n",
    "        \"example_id\": int(example.example_id),\n",
    "        \"short_spans\": short_spans,\n",
    "        \"long_spans\": long_spans\n",
    "    }\n",
    "\n",
    "    return predictions_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "def compute_pred_dict(candidates_dict, dev_features, raw_results,tqdm=None):\n",
    "    \"\"\"Computes official answer key from raw logits.\"\"\"\n",
    "    raw_results_by_id = [(int(res.unique_id),1, res) for res in raw_results]\n",
    "\n",
    "    examples_by_id = [(int(k),0,v) for k, v in candidates_dict.items()]\n",
    "  \n",
    "    features_by_id = [(int(d['unique_id']),2,d) for d in dev_features] \n",
    "  \n",
    "    # Join examples with features and raw results.\n",
    "    examples = []\n",
    "    print('merging examples...')\n",
    "    merged = sorted(examples_by_id + raw_results_by_id + features_by_id)\n",
    "    print('done.')\n",
    "    for idx, type_, datum in merged:\n",
    "        if type_==0: #isinstance(datum, list):\n",
    "            examples.append(EvalExample(idx, datum))\n",
    "        elif type_==2: #\"token_map\" in datum:\n",
    "            examples[-1].features[idx] = datum\n",
    "        else:\n",
    "            examples[-1].results[idx] = datum\n",
    "\n",
    "    # Construct prediction objects.\n",
    "    print('Computing predictions...')\n",
    "   \n",
    "    nq_pred_dict = {}\n",
    "    if tqdm is not None:\n",
    "        examples = tqdm(examples)\n",
    "    for e in examples:\n",
    "        predictions_summary = compute_predictions(e)\n",
    "        nq_pred_dict[e.example_id] = predictions_summary\n",
    "    return nq_pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "def read_candidates_from_one_split(input_path):\n",
    "  \"\"\"Read candidates from a single jsonl file.\"\"\"\n",
    "  candidates_dict = {}\n",
    "  print(\"Reading examples from: %s\" % input_path)\n",
    "  if input_path.endswith(\".gz\"):\n",
    "    with gzip.GzipFile(fileobj=tf.io.gfile.GFile(input_path, \"rb\")) as input_file:\n",
    "      for index, line in enumerate(input_file):\n",
    "        e = json.loads(line)\n",
    "        candidates_dict[e[\"example_id\"]] = e[\"long_answer_candidates\"]\n",
    "        \n",
    "  else:\n",
    "    with tf.io.gfile.GFile(input_path, \"r\") as input_file:\n",
    "      for index, line in enumerate(input_file):\n",
    "        e = json.loads(line)\n",
    "        candidates_dict[e[\"example_id\"]] = e[\"long_answer_candidates\"] # testar juntando com question_text\n",
    "  return candidates_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_candidates(input_pattern):\n",
    "  \"\"\"Read candidates with real multiple processes.\"\"\"\n",
    "  input_paths = tf.io.gfile.glob(input_pattern)\n",
    "  final_dict = {}\n",
    "  for input_path in input_paths:\n",
    "    final_dict.update(read_candidates_from_one_split(input_path))\n",
    "  return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28308"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading eval_features\n",
    "import pickle\n",
    "eval_features = []\n",
    "with open('../output/1k/eval_features.pkl', 'rb') as f:\n",
    "    eval_features = pickle.load(f)\n",
    "len(eval_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading result\n",
    "# 'uniqe_id','start_logits','end_logits','answer_type_logits'\n",
    "result_file = np.load('../output/1k/bert-joint-baseline-output.npz')\n",
    "result = [result_file['uniqe_id'], result_file['start_logits'], result_file['end_logits'],\n",
    "          result_file['answer_type_logits']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to candidates file\n",
      "Reading examples from: ../output/1k/nq-train-part.jsonl\n",
      "setting up eval features\n",
      "compute_pred_dict\n",
      "merging examples...\n",
      "done.\n",
      "Computing predictions...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "all_results = [bert_utils.RawResult(*x) for x in zip(*result)]\n",
    "    \n",
    "print (\"Going to candidates file\")\n",
    "\n",
    "# for debug\n",
    "#candidates_dict = read_candidates('../input/tensorflow2-question-answering/simplified-nq-test.jsonl')\n",
    "candidates_dict = read_candidates('../output/1k/nq-train-part.jsonl')\n",
    "\n",
    "print (\"setting up eval features\")\n",
    "\n",
    "# for debug\n",
    "#eval_features = list(token_map_ds)\n",
    "\n",
    "print (\"compute_pred_dict\")\n",
    "\n",
    "#tqdm_notebook= tqdm.tqdm_notebook\n",
    "tqdm_notebook= None\n",
    "nq_pred_dict = compute_pred_dict(candidates_dict,\n",
    "                                 eval_features,\n",
    "                                 all_results,\n",
    "                                 tqdm=tqdm_notebook)\n",
    "\n",
    "predictions_json = {\"predictions\": list(nq_pred_dict.values())}\n",
    "\n",
    "# print (\"writing json\")\n",
    "\n",
    "# with tf.io.gfile.GFile('../output/predictions-local.json', \"w\") as f:\n",
    "#     json.dump(predictions_json, f, indent=4)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'example_id': -9209839852162522524, 'short_sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'example_id': -9188885911445781635, 'short_sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'example_id': -9111510312671706854, 'short_sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'example_id': -9110190923673509457, 'short_sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'example_id': -9100123296297706673, 'short_sp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         predictions\n",
       "0  {'example_id': -9209839852162522524, 'short_sp...\n",
       "1  {'example_id': -9188885911445781635, 'short_sp...\n",
       "2  {'example_id': -9111510312671706854, 'short_sp...\n",
       "3  {'example_id': -9110190923673509457, 'short_sp...\n",
       "4  {'example_id': -9100123296297706673, 'short_sp..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for debug\n",
    "#answers_df = pd.read_json(\"../working/predictions.json\")\n",
    "# answers_df = pd.read_json(\"../output/predictions-local.json\")\n",
    "answers_df = pd.DataFrame.from_dict(predictions_json)\n",
    "answers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### {long score > 2, cont = 5 | short score > 2, cont = 5} = 0.18\n",
    "# { long score > 2, cont = 5 | short score > 6, cont = 5}\n",
    "# { long score > 2, cont = 1 | short score > 6, cont = 5}\n",
    "\n",
    "def df_long_index_score(df):\n",
    "    answers = []\n",
    "    cont = 0\n",
    "    for e in df['long_spans']:\n",
    "        # if score > 2\n",
    "        if e[2] > 3: \n",
    "            index = {}\n",
    "            index['start'] = e[0]\n",
    "            index['end'] = e[1]\n",
    "            index['score'] = e[2]\n",
    "            answers.append(index)\n",
    "            cont += 1\n",
    "        # number of answers\n",
    "        if cont == 1:\n",
    "            break\n",
    "            \n",
    "    return answers\n",
    "\n",
    "def df_short_index_score(df):\n",
    "    answers = []\n",
    "    cont = 0\n",
    "    for e in df['short_spans']:\n",
    "        # if score > 2\n",
    "        if e[2] > 8:\n",
    "            index = {}\n",
    "            index['start'] = e[0]\n",
    "            index['end'] = e[1]\n",
    "            index['score'] = e[2]\n",
    "            answers.append(index)\n",
    "            cont += 1\n",
    "        # number of answers\n",
    "        if cont == 1:\n",
    "            break\n",
    "            \n",
    "    return answers\n",
    "\n",
    "def df_example_id(df):\n",
    "    return df['example_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>example_id</th>\n",
       "      <th>long_indexes_and_scores</th>\n",
       "      <th>short_indexes_and_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'example_id': -9209839852162522524, 'short_sp...</td>\n",
       "      <td>-9209839852162522524</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'example_id': -9188885911445781635, 'short_sp...</td>\n",
       "      <td>-9188885911445781635</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'example_id': -9111510312671706854, 'short_sp...</td>\n",
       "      <td>-9111510312671706854</td>\n",
       "      <td>[{'start': 189, 'end': 282, 'score': 8.9754791...</td>\n",
       "      <td>[{'start': 262, 'end': 266, 'score': 8.9754791...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'example_id': -9110190923673509457, 'short_sp...</td>\n",
       "      <td>-9110190923673509457</td>\n",
       "      <td>[{'start': 201, 'end': 329, 'score': 8.1631450...</td>\n",
       "      <td>[{'start': 202, 'end': 215, 'score': 8.1631450...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'example_id': -9100123296297706673, 'short_sp...</td>\n",
       "      <td>-9100123296297706673</td>\n",
       "      <td>[{'start': 519, 'end': 620, 'score': 12.078039...</td>\n",
       "      <td>[{'start': 598, 'end': 601, 'score': 12.078039...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         predictions           example_id  \\\n",
       "0  {'example_id': -9209839852162522524, 'short_sp... -9209839852162522524   \n",
       "1  {'example_id': -9188885911445781635, 'short_sp... -9188885911445781635   \n",
       "2  {'example_id': -9111510312671706854, 'short_sp... -9111510312671706854   \n",
       "3  {'example_id': -9110190923673509457, 'short_sp... -9110190923673509457   \n",
       "4  {'example_id': -9100123296297706673, 'short_sp... -9100123296297706673   \n",
       "\n",
       "                             long_indexes_and_scores  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [{'start': 189, 'end': 282, 'score': 8.9754791...   \n",
       "3  [{'start': 201, 'end': 329, 'score': 8.1631450...   \n",
       "4  [{'start': 519, 'end': 620, 'score': 12.078039...   \n",
       "\n",
       "                            short_indexes_and_scores  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2  [{'start': 262, 'end': 266, 'score': 8.9754791...  \n",
       "3  [{'start': 202, 'end': 215, 'score': 8.1631450...  \n",
       "4  [{'start': 598, 'end': 601, 'score': 12.078039...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_df['example_id'] = answers_df['predictions'].apply(df_example_id)\n",
    "\n",
    "answers_df['long_indexes_and_scores'] = answers_df['predictions'].apply(df_long_index_score)\n",
    "\n",
    "answers_df['short_indexes_and_scores'] = answers_df['predictions'].apply(df_short_index_score)\n",
    "\n",
    "answers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>example_id</th>\n",
       "      <th>long_indexes_and_scores</th>\n",
       "      <th>short_indexes_and_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'example_id': -9209839852162522524, 'short_sp...</td>\n",
       "      <td>-9209839852162522524</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'example_id': -9188885911445781635, 'short_sp...</td>\n",
       "      <td>-9188885911445781635</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'example_id': -9111510312671706854, 'short_sp...</td>\n",
       "      <td>-9111510312671706854</td>\n",
       "      <td>[{'start': 189, 'end': 282, 'score': 8.9754791...</td>\n",
       "      <td>[{'start': 262, 'end': 266, 'score': 8.9754791...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'example_id': -9110190923673509457, 'short_sp...</td>\n",
       "      <td>-9110190923673509457</td>\n",
       "      <td>[{'start': 201, 'end': 329, 'score': 8.1631450...</td>\n",
       "      <td>[{'start': 202, 'end': 215, 'score': 8.1631450...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'example_id': -9100123296297706673, 'short_sp...</td>\n",
       "      <td>-9100123296297706673</td>\n",
       "      <td>[{'start': 519, 'end': 620, 'score': 12.078039...</td>\n",
       "      <td>[{'start': 598, 'end': 601, 'score': 12.078039...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         predictions           example_id  \\\n",
       "0  {'example_id': -9209839852162522524, 'short_sp... -9209839852162522524   \n",
       "1  {'example_id': -9188885911445781635, 'short_sp... -9188885911445781635   \n",
       "2  {'example_id': -9111510312671706854, 'short_sp... -9111510312671706854   \n",
       "3  {'example_id': -9110190923673509457, 'short_sp... -9110190923673509457   \n",
       "4  {'example_id': -9100123296297706673, 'short_sp... -9100123296297706673   \n",
       "\n",
       "                             long_indexes_and_scores  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [{'start': 189, 'end': 282, 'score': 8.9754791...   \n",
       "3  [{'start': 201, 'end': 329, 'score': 8.1631450...   \n",
       "4  [{'start': 519, 'end': 620, 'score': 12.078039...   \n",
       "\n",
       "                            short_indexes_and_scores  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2  [{'start': 262, 'end': 266, 'score': 8.9754791...  \n",
       "3  [{'start': 202, 'end': 215, 'score': 8.1631450...  \n",
       "4  [{'start': 598, 'end': 601, 'score': 12.078039...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#answers_df = answers_df.drop(['predictions'], axis=1)\n",
    "answers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_answer(entry):\n",
    "    answer = []\n",
    "    for e in entry:\n",
    "        answer.append(str(e['start']) + ':'+ str(e['end']))\n",
    "    if not answer:\n",
    "        answer = \"\"\n",
    "    return \", \".join(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>example_id</th>\n",
       "      <th>long_indexes_and_scores</th>\n",
       "      <th>short_indexes_and_scores</th>\n",
       "      <th>long_answer</th>\n",
       "      <th>short_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'example_id': -9209839852162522524, 'short_sp...</td>\n",
       "      <td>-9209839852162522524</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'example_id': -9188885911445781635, 'short_sp...</td>\n",
       "      <td>-9188885911445781635</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'example_id': -9111510312671706854, 'short_sp...</td>\n",
       "      <td>-9111510312671706854</td>\n",
       "      <td>[{'start': 189, 'end': 282, 'score': 8.9754791...</td>\n",
       "      <td>[{'start': 262, 'end': 266, 'score': 8.9754791...</td>\n",
       "      <td>189:282</td>\n",
       "      <td>262:266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'example_id': -9110190923673509457, 'short_sp...</td>\n",
       "      <td>-9110190923673509457</td>\n",
       "      <td>[{'start': 201, 'end': 329, 'score': 8.1631450...</td>\n",
       "      <td>[{'start': 202, 'end': 215, 'score': 8.1631450...</td>\n",
       "      <td>201:329</td>\n",
       "      <td>202:215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'example_id': -9100123296297706673, 'short_sp...</td>\n",
       "      <td>-9100123296297706673</td>\n",
       "      <td>[{'start': 519, 'end': 620, 'score': 12.078039...</td>\n",
       "      <td>[{'start': 598, 'end': 601, 'score': 12.078039...</td>\n",
       "      <td>519:620</td>\n",
       "      <td>598:601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         predictions            example_id  \\\n",
       "0  {'example_id': -9209839852162522524, 'short_sp...  -9209839852162522524   \n",
       "1  {'example_id': -9188885911445781635, 'short_sp...  -9188885911445781635   \n",
       "2  {'example_id': -9111510312671706854, 'short_sp...  -9111510312671706854   \n",
       "3  {'example_id': -9110190923673509457, 'short_sp...  -9110190923673509457   \n",
       "4  {'example_id': -9100123296297706673, 'short_sp...  -9100123296297706673   \n",
       "\n",
       "                             long_indexes_and_scores  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [{'start': 189, 'end': 282, 'score': 8.9754791...   \n",
       "3  [{'start': 201, 'end': 329, 'score': 8.1631450...   \n",
       "4  [{'start': 519, 'end': 620, 'score': 12.078039...   \n",
       "\n",
       "                            short_indexes_and_scores long_answer short_answer  \n",
       "0                                                 []                           \n",
       "1                                                 []                           \n",
       "2  [{'start': 262, 'end': 266, 'score': 8.9754791...     189:282      262:266  \n",
       "3  [{'start': 202, 'end': 215, 'score': 8.1631450...     201:329      202:215  \n",
       "4  [{'start': 598, 'end': 601, 'score': 12.078039...     519:620      598:601  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_df[\"long_answer\"] = answers_df['long_indexes_and_scores'].apply(create_answer)\n",
    "answers_df[\"short_answer\"] = answers_df['short_indexes_and_scores'].apply(create_answer)\n",
    "answers_df[\"example_id\"] = answers_df['example_id'].apply(lambda q: str(q))\n",
    "\n",
    "long_answers = dict(zip(answers_df[\"example_id\"], answers_df[\"long_answer\"]))\n",
    "short_answers = dict(zip(answers_df[\"example_id\"], answers_df[\"short_answer\"]))\n",
    "\n",
    "answers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>example_id</th>\n",
       "      <th>long_answer</th>\n",
       "      <th>short_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'example_id': -9209839852162522524, 'short_sp...</td>\n",
       "      <td>-9209839852162522524</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'example_id': -9188885911445781635, 'short_sp...</td>\n",
       "      <td>-9188885911445781635</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'example_id': -9111510312671706854, 'short_sp...</td>\n",
       "      <td>-9111510312671706854</td>\n",
       "      <td>189:282</td>\n",
       "      <td>262:266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'example_id': -9110190923673509457, 'short_sp...</td>\n",
       "      <td>-9110190923673509457</td>\n",
       "      <td>201:329</td>\n",
       "      <td>202:215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'example_id': -9100123296297706673, 'short_sp...</td>\n",
       "      <td>-9100123296297706673</td>\n",
       "      <td>519:620</td>\n",
       "      <td>598:601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         predictions            example_id  \\\n",
       "0  {'example_id': -9209839852162522524, 'short_sp...  -9209839852162522524   \n",
       "1  {'example_id': -9188885911445781635, 'short_sp...  -9188885911445781635   \n",
       "2  {'example_id': -9111510312671706854, 'short_sp...  -9111510312671706854   \n",
       "3  {'example_id': -9110190923673509457, 'short_sp...  -9110190923673509457   \n",
       "4  {'example_id': -9100123296297706673, 'short_sp...  -9100123296297706673   \n",
       "\n",
       "  long_answer short_answer  \n",
       "0                           \n",
       "1                           \n",
       "2     189:282      262:266  \n",
       "3     201:329      202:215  \n",
       "4     519:620      598:601  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_df = answers_df.drop(['long_indexes_and_scores', 'short_indexes_and_scores'], axis=1)\n",
    "answers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>example_id</th>\n",
       "      <th>long_answer</th>\n",
       "      <th>short_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [predictions, example_id, long_answer, short_answer]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_df.query(\"short_answer == 'NO'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debug\n",
    "#answers_df.to_csv('test_answers_df.csv', index=False)\n",
    "answers_df.to_csv('../output/test_answers_df_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_kg_hide-input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('-1011141123527297803', 'occurred at index 0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2211ffe7553f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/tensorflow2-question-answering/sample_submission.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlong_prediction_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"example_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_long\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlong_answers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"example_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_long\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mshort_prediction_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"example_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_short\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mshort_answers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"example_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_short\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/kaggle_tf2_question_answering/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6926\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6927\u001b[0m         )\n\u001b[0;32m-> 6928\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6930\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/kaggle_tf2_question_answering/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/kaggle_tf2_question_answering/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# compute the result using the series generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/kaggle_tf2_question_answering/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-2211ffe7553f>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/tensorflow2-question-answering/sample_submission.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlong_prediction_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"example_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_long\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlong_answers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"example_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_long\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mshort_prediction_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"example_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_short\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mshort_answers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"example_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_short\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('-1011141123527297803', 'occurred at index 0')"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"../input/tensorflow2-question-answering/sample_submission.csv\")\n",
    "\n",
    "long_prediction_strings = sample_submission[sample_submission[\"example_id\"].str.contains(\"_long\")].apply(lambda q: long_answers[q[\"example_id\"].replace(\"_long\", \"\")], axis=1)\n",
    "short_prediction_strings = sample_submission[sample_submission[\"example_id\"].str.contains(\"_short\")].apply(lambda q: short_answers[q[\"example_id\"].replace(\"_short\", \"\")], axis=1)\n",
    "\n",
    "sample_submission.loc[sample_submission[\"example_id\"].str.contains(\"_long\"), \"PredictionString\"] = long_prediction_strings\n",
    "sample_submission.loc[sample_submission[\"example_id\"].str.contains(\"_short\"), \"PredictionString\"] = short_prediction_strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1011141123527297803_long</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1011141123527297803_short</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1028916936938579349_long</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1028916936938579349_short</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1055197305756217938_long</td>\n",
       "      <td>221:335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>930196817123445627_short</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>934950704129184964_long</td>\n",
       "      <td>496:616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>934950704129184964_short</td>\n",
       "      <td>515:517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>958723574737344087_long</td>\n",
       "      <td>938:2597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>958723574737344087_short</td>\n",
       "      <td>1704:1706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>692 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     example_id PredictionString\n",
       "0     -1011141123527297803_long                 \n",
       "1    -1011141123527297803_short                 \n",
       "2     -1028916936938579349_long                 \n",
       "3    -1028916936938579349_short                 \n",
       "4     -1055197305756217938_long          221:335\n",
       "..                          ...              ...\n",
       "687    930196817123445627_short                 \n",
       "688     934950704129184964_long          496:616\n",
       "689    934950704129184964_short          515:517\n",
       "690     958723574737344087_long         938:2597\n",
       "691    958723574737344087_short        1704:1706\n",
       "\n",
       "[692 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "19632e0fc9ec4801aa590c5e03457927": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5ee1c3350b184cfaad9f3cd8e736eccf",
       "placeholder": "​",
       "style": "IPY_MODEL_8b453d9f7f3546cca4a1b6490e3286ac",
       "value": " 346/346 [00:02&lt;00:00, 122.67it/s]"
      }
     },
     "1ce4aefdc6c44c7780ea34e29b008122": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "240761f153cc426f84d079729027ef1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3e38ea5bdc444974a5e611f0852a336d",
        "IPY_MODEL_19632e0fc9ec4801aa590c5e03457927"
       ],
       "layout": "IPY_MODEL_99843c4b80c54a8f9bfd9173af9b1d6b"
      }
     },
     "3e38ea5bdc444974a5e611f0852a336d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a05735f52a3046ba8dc996720fb91476",
       "max": 346,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1ce4aefdc6c44c7780ea34e29b008122",
       "value": 346
      }
     },
     "5ee1c3350b184cfaad9f3cd8e736eccf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8b453d9f7f3546cca4a1b6490e3286ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "99843c4b80c54a8f9bfd9173af9b1d6b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a05735f52a3046ba8dc996720fb91476": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
